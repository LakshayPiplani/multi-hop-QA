{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.99352983465133,
  "eval_steps": 500,
  "global_step": 3475,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07189072609633357,
      "grad_norm": 25.257659912109375,
      "learning_rate": 1.9717985611510793e-05,
      "loss": 8.8503,
      "step": 50
    },
    {
      "epoch": 0.14378145219266714,
      "grad_norm": 9.401609420776367,
      "learning_rate": 1.943021582733813e-05,
      "loss": 4.5882,
      "step": 100
    },
    {
      "epoch": 0.21567217828900073,
      "grad_norm": 2.764324188232422,
      "learning_rate": 1.9148201438848922e-05,
      "loss": 3.2932,
      "step": 150
    },
    {
      "epoch": 0.2875629043853343,
      "grad_norm": 4.218076229095459,
      "learning_rate": 1.8860431654676262e-05,
      "loss": 2.8427,
      "step": 200
    },
    {
      "epoch": 0.35945363048166784,
      "grad_norm": 5.973977565765381,
      "learning_rate": 1.85726618705036e-05,
      "loss": 2.3985,
      "step": 250
    },
    {
      "epoch": 0.43134435657800146,
      "grad_norm": 7.131888389587402,
      "learning_rate": 1.8284892086330936e-05,
      "loss": 2.2313,
      "step": 300
    },
    {
      "epoch": 0.503235082674335,
      "grad_norm": 10.54545783996582,
      "learning_rate": 1.7997122302158273e-05,
      "loss": 2.0611,
      "step": 350
    },
    {
      "epoch": 0.5751258087706685,
      "grad_norm": 6.319669246673584,
      "learning_rate": 1.7715107913669065e-05,
      "loss": 1.9366,
      "step": 400
    },
    {
      "epoch": 0.6470165348670022,
      "grad_norm": 6.214553356170654,
      "learning_rate": 1.7427338129496405e-05,
      "loss": 1.875,
      "step": 450
    },
    {
      "epoch": 0.7189072609633357,
      "grad_norm": 23.503902435302734,
      "learning_rate": 1.7139568345323742e-05,
      "loss": 1.8336,
      "step": 500
    },
    {
      "epoch": 0.7907979870596693,
      "grad_norm": 13.114710807800293,
      "learning_rate": 1.685179856115108e-05,
      "loss": 1.8071,
      "step": 550
    },
    {
      "epoch": 0.8626887131560029,
      "grad_norm": 20.724361419677734,
      "learning_rate": 1.656402877697842e-05,
      "loss": 1.7502,
      "step": 600
    },
    {
      "epoch": 0.9345794392523364,
      "grad_norm": 8.444754600524902,
      "learning_rate": 1.6276258992805756e-05,
      "loss": 1.719,
      "step": 650
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.0259039402008057,
      "eval_runtime": 319.2706,
      "eval_samples_per_second": 6.537,
      "eval_steps_per_second": 6.537,
      "step": 696
    },
    {
      "epoch": 1.0057512580877066,
      "grad_norm": 9.687490463256836,
      "learning_rate": 1.5988489208633096e-05,
      "loss": 1.737,
      "step": 700
    },
    {
      "epoch": 1.0776419841840403,
      "grad_norm": 13.19420337677002,
      "learning_rate": 1.5700719424460433e-05,
      "loss": 1.6995,
      "step": 750
    },
    {
      "epoch": 1.1495327102803738,
      "grad_norm": 16.85175895690918,
      "learning_rate": 1.541294964028777e-05,
      "loss": 1.6801,
      "step": 800
    },
    {
      "epoch": 1.2214234363767074,
      "grad_norm": 10.88700008392334,
      "learning_rate": 1.5125179856115109e-05,
      "loss": 1.6567,
      "step": 850
    },
    {
      "epoch": 1.2933141624730409,
      "grad_norm": 6.959936618804932,
      "learning_rate": 1.4837410071942446e-05,
      "loss": 1.597,
      "step": 900
    },
    {
      "epoch": 1.3652048885693746,
      "grad_norm": 13.452219009399414,
      "learning_rate": 1.4549640287769786e-05,
      "loss": 1.5747,
      "step": 950
    },
    {
      "epoch": 1.4370956146657081,
      "grad_norm": 7.830167293548584,
      "learning_rate": 1.4261870503597124e-05,
      "loss": 1.5854,
      "step": 1000
    },
    {
      "epoch": 1.5089863407620419,
      "grad_norm": 17.73402976989746,
      "learning_rate": 1.3974100719424461e-05,
      "loss": 1.5525,
      "step": 1050
    },
    {
      "epoch": 1.5808770668583754,
      "grad_norm": 18.659963607788086,
      "learning_rate": 1.36863309352518e-05,
      "loss": 1.5294,
      "step": 1100
    },
    {
      "epoch": 1.6527677929547089,
      "grad_norm": 13.810235023498535,
      "learning_rate": 1.3398561151079137e-05,
      "loss": 1.5034,
      "step": 1150
    },
    {
      "epoch": 1.7246585190510424,
      "grad_norm": 21.66543960571289,
      "learning_rate": 1.3110791366906477e-05,
      "loss": 1.485,
      "step": 1200
    },
    {
      "epoch": 1.796549245147376,
      "grad_norm": 34.832969665527344,
      "learning_rate": 1.2823021582733814e-05,
      "loss": 1.4659,
      "step": 1250
    },
    {
      "epoch": 1.8684399712437094,
      "grad_norm": 9.841636657714844,
      "learning_rate": 1.2535251798561152e-05,
      "loss": 1.4584,
      "step": 1300
    },
    {
      "epoch": 1.9403306973400432,
      "grad_norm": 19.665456771850586,
      "learning_rate": 1.224748201438849e-05,
      "loss": 1.4952,
      "step": 1350
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.383370876312256,
      "eval_runtime": 149.822,
      "eval_samples_per_second": 13.93,
      "eval_steps_per_second": 13.93,
      "step": 1392
    },
    {
      "epoch": 2.011502516175413,
      "grad_norm": 9.46822452545166,
      "learning_rate": 1.1959712230215828e-05,
      "loss": 1.4427,
      "step": 1400
    },
    {
      "epoch": 2.083393242271747,
      "grad_norm": 8.282674789428711,
      "learning_rate": 1.1671942446043168e-05,
      "loss": 1.4575,
      "step": 1450
    },
    {
      "epoch": 2.1552839683680807,
      "grad_norm": 11.255389213562012,
      "learning_rate": 1.1384172661870505e-05,
      "loss": 1.4386,
      "step": 1500
    },
    {
      "epoch": 2.227174694464414,
      "grad_norm": 18.590551376342773,
      "learning_rate": 1.1096402877697842e-05,
      "loss": 1.451,
      "step": 1550
    },
    {
      "epoch": 2.2990654205607477,
      "grad_norm": 21.359477996826172,
      "learning_rate": 1.080863309352518e-05,
      "loss": 1.4169,
      "step": 1600
    },
    {
      "epoch": 2.370956146657081,
      "grad_norm": 27.955963134765625,
      "learning_rate": 1.0520863309352517e-05,
      "loss": 1.437,
      "step": 1650
    },
    {
      "epoch": 2.4428468727534147,
      "grad_norm": 23.118663787841797,
      "learning_rate": 1.0233093525179858e-05,
      "loss": 1.418,
      "step": 1700
    },
    {
      "epoch": 2.5147375988497482,
      "grad_norm": 8.69240951538086,
      "learning_rate": 9.945323741007195e-06,
      "loss": 1.4029,
      "step": 1750
    },
    {
      "epoch": 2.5866283249460817,
      "grad_norm": 9.587646484375,
      "learning_rate": 9.657553956834533e-06,
      "loss": 1.4122,
      "step": 1800
    },
    {
      "epoch": 2.6585190510424157,
      "grad_norm": 14.468890190124512,
      "learning_rate": 9.369784172661872e-06,
      "loss": 1.3968,
      "step": 1850
    },
    {
      "epoch": 2.730409777138749,
      "grad_norm": 8.549091339111328,
      "learning_rate": 9.08201438848921e-06,
      "loss": 1.4441,
      "step": 1900
    },
    {
      "epoch": 2.8023005032350827,
      "grad_norm": 9.453075408935547,
      "learning_rate": 8.794244604316547e-06,
      "loss": 1.393,
      "step": 1950
    },
    {
      "epoch": 2.8741912293314162,
      "grad_norm": 18.317760467529297,
      "learning_rate": 8.506474820143886e-06,
      "loss": 1.3639,
      "step": 2000
    },
    {
      "epoch": 2.9460819554277498,
      "grad_norm": 10.898392677307129,
      "learning_rate": 8.218705035971224e-06,
      "loss": 1.4063,
      "step": 2050
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.6039392948150635,
      "eval_runtime": 149.5402,
      "eval_samples_per_second": 13.956,
      "eval_steps_per_second": 13.956,
      "step": 2088
    },
    {
      "epoch": 3.01725377426312,
      "grad_norm": 17.34918212890625,
      "learning_rate": 7.930935251798561e-06,
      "loss": 1.3798,
      "step": 2100
    },
    {
      "epoch": 3.0891445003594535,
      "grad_norm": 19.708133697509766,
      "learning_rate": 7.6431654676259e-06,
      "loss": 1.3918,
      "step": 2150
    },
    {
      "epoch": 3.161035226455787,
      "grad_norm": 14.612675666809082,
      "learning_rate": 7.3553956834532385e-06,
      "loss": 1.4013,
      "step": 2200
    },
    {
      "epoch": 3.2329259525521206,
      "grad_norm": 11.934529304504395,
      "learning_rate": 7.067625899280575e-06,
      "loss": 1.3938,
      "step": 2250
    },
    {
      "epoch": 3.3048166786484545,
      "grad_norm": 14.2335205078125,
      "learning_rate": 6.779856115107915e-06,
      "loss": 1.3507,
      "step": 2300
    },
    {
      "epoch": 3.376707404744788,
      "grad_norm": 10.364920616149902,
      "learning_rate": 6.4920863309352525e-06,
      "loss": 1.4001,
      "step": 2350
    },
    {
      "epoch": 3.4485981308411215,
      "grad_norm": 22.0673885345459,
      "learning_rate": 6.2100719424460434e-06,
      "loss": 1.3662,
      "step": 2400
    },
    {
      "epoch": 3.520488856937455,
      "grad_norm": 10.87657356262207,
      "learning_rate": 5.922302158273382e-06,
      "loss": 1.344,
      "step": 2450
    },
    {
      "epoch": 3.5923795830337886,
      "grad_norm": 9.300776481628418,
      "learning_rate": 5.63453237410072e-06,
      "loss": 1.3673,
      "step": 2500
    },
    {
      "epoch": 3.664270309130122,
      "grad_norm": 15.938553810119629,
      "learning_rate": 5.346762589928058e-06,
      "loss": 1.3536,
      "step": 2550
    },
    {
      "epoch": 3.7361610352264556,
      "grad_norm": 11.134344100952148,
      "learning_rate": 5.058992805755396e-06,
      "loss": 1.3336,
      "step": 2600
    },
    {
      "epoch": 3.8080517613227896,
      "grad_norm": 12.798258781433105,
      "learning_rate": 4.771223021582735e-06,
      "loss": 1.377,
      "step": 2650
    },
    {
      "epoch": 3.879942487419123,
      "grad_norm": 10.425095558166504,
      "learning_rate": 4.483453237410072e-06,
      "loss": 1.3499,
      "step": 2700
    },
    {
      "epoch": 3.9518332135154566,
      "grad_norm": 15.79041862487793,
      "learning_rate": 4.19568345323741e-06,
      "loss": 1.337,
      "step": 2750
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.7514872550964355,
      "eval_runtime": 149.7838,
      "eval_samples_per_second": 13.933,
      "eval_steps_per_second": 13.933,
      "step": 2784
    },
    {
      "epoch": 4.023005032350826,
      "grad_norm": 17.922943115234375,
      "learning_rate": 3.907913669064749e-06,
      "loss": 1.3307,
      "step": 2800
    },
    {
      "epoch": 4.09489575844716,
      "grad_norm": 29.77406883239746,
      "learning_rate": 3.620143884892087e-06,
      "loss": 1.33,
      "step": 2850
    },
    {
      "epoch": 4.166786484543494,
      "grad_norm": 15.138517379760742,
      "learning_rate": 3.332374100719425e-06,
      "loss": 1.3403,
      "step": 2900
    },
    {
      "epoch": 4.238677210639827,
      "grad_norm": 9.74780559539795,
      "learning_rate": 3.0446043165467628e-06,
      "loss": 1.3438,
      "step": 2950
    },
    {
      "epoch": 4.310567936736161,
      "grad_norm": 10.237380027770996,
      "learning_rate": 2.756834532374101e-06,
      "loss": 1.3558,
      "step": 3000
    },
    {
      "epoch": 4.382458662832494,
      "grad_norm": 14.5248384475708,
      "learning_rate": 2.469064748201439e-06,
      "loss": 1.3635,
      "step": 3050
    },
    {
      "epoch": 4.454349388928828,
      "grad_norm": 27.87557601928711,
      "learning_rate": 2.1812949640287772e-06,
      "loss": 1.3327,
      "step": 3100
    },
    {
      "epoch": 4.526240115025161,
      "grad_norm": 16.975406646728516,
      "learning_rate": 1.8935251798561152e-06,
      "loss": 1.3109,
      "step": 3150
    },
    {
      "epoch": 4.598130841121495,
      "grad_norm": 15.089909553527832,
      "learning_rate": 1.6057553956834535e-06,
      "loss": 1.3264,
      "step": 3200
    },
    {
      "epoch": 4.6700215672178285,
      "grad_norm": 18.4334659576416,
      "learning_rate": 1.3179856115107915e-06,
      "loss": 1.3311,
      "step": 3250
    },
    {
      "epoch": 4.741912293314162,
      "grad_norm": 23.326871871948242,
      "learning_rate": 1.0302158273381296e-06,
      "loss": 1.3364,
      "step": 3300
    },
    {
      "epoch": 4.813803019410496,
      "grad_norm": 12.55801010131836,
      "learning_rate": 7.424460431654677e-07,
      "loss": 1.329,
      "step": 3350
    },
    {
      "epoch": 4.885693745506829,
      "grad_norm": 18.558652877807617,
      "learning_rate": 4.546762589928058e-07,
      "loss": 1.3511,
      "step": 3400
    },
    {
      "epoch": 4.957584471603163,
      "grad_norm": 12.11301040649414,
      "learning_rate": 1.669064748201439e-07,
      "loss": 1.3247,
      "step": 3450
    },
    {
      "epoch": 4.99352983465133,
      "eval_loss": 2.79263973236084,
      "eval_runtime": 149.8712,
      "eval_samples_per_second": 13.925,
      "eval_steps_per_second": 13.925,
      "step": 3475
    }
  ],
  "logging_steps": 50,
  "max_steps": 3475,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.9879872285179904e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
